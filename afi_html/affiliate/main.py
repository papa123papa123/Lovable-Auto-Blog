# -*- coding: utf-8 -*-
"""
ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ç”Ÿæˆãƒ¡ã‚¤ãƒ³å‡¦ç†
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Tuple
import json
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed

# Windowsç’°å¢ƒã§ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¨­å®š
if sys.platform == "win32":
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    os.environ['PYTHONUTF8'] = '1'

from .extractor import (
    extract_amazon_products_from_html,
    extract_rakuten_products_from_html,
    detect_product_type
)
from .link_generator import (
    create_amazon_affiliate_link,
    create_rakuten_affiliate_link
)
from .product_fetcher import (
    get_amazon_product_info,
    get_rakuten_product_info
)


def generate_amazon_affiliate_links(
    html_path: Path,
    associate_id: str = "",
    skip_count: int = 4,
    fetch_details: bool = False
) -> List[Dict[str, str]]:
    """Amazon HTMLã‹ã‚‰ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    products_with_titles = extract_amazon_products_from_html(html_path)
    
    if not products_with_titles:
        print("âš ï¸ Amazonå•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return []
    
    print(f"âœ… {len(products_with_titles)}ä»¶ã®Amazonå•†å“ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
    
    product_asins = products_with_titles[skip_count:]
    
    if not product_asins:
        print("âš ï¸ å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆåºƒå‘Šé™¤å¤–å¾Œï¼‰")
        return []
    
    print(f"ðŸ“¦ {len(product_asins)}ä»¶ã®å•†å“ã‚’å‡¦ç†ã—ã¾ã™ï¼ˆåºƒå‘Š{skip_count}ä»¶ã‚’é™¤å¤–ï¼‰")
    
    products = []
    
    if fetch_details:
        def fetch_product_info(asin: str, title_from_html: str) -> Tuple[str, Dict]:
            try:
                product_info = get_amazon_product_info(asin)
                if not product_info.get("title") or len(product_info.get("title", "")) < 5:
                    product_info["title"] = title_from_html
                return (asin, product_info)
            except Exception:
                return (asin, {
                    "asin": asin,
                    "title": title_from_html,
                    "url": f"https://www.amazon.co.jp/dp/{asin}",
                    "price": "",
                    "image_url": ""
                })
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = {
                executor.submit(fetch_product_info, asin, title): (asin, title)
                for asin, title in product_asins
            }
            
            for future in as_completed(futures.keys()):
                asin, title = futures[future]
                asin_result, product_info = future.result()
                products.append({
                    "index": len(products) + 1,
                    "asin": asin,
                    "title": product_info.get("title", title),
                    "price": product_info.get("price", ""),
                    "image_url": product_info.get("image_url", ""),
                    "affiliate_link": create_amazon_affiliate_link(asin, associate_id),
                    "amazon_url": product_info.get("url", f"https://www.amazon.co.jp/dp/{asin}")
                })
    else:
        for idx, (asin, title) in enumerate(product_asins, 1):
            products.append({
                "index": idx,
                "asin": asin,
                "title": title,
                "price": "",
                "image_url": "",
                "affiliate_link": create_amazon_affiliate_link(asin, associate_id),
                "amazon_url": f"https://www.amazon.co.jp/dp/{asin}"
            })
    
    return products


def generate_rakuten_affiliate_links(
    html_path: Path,
    affiliate_id: str = "",
    skip_count: int = 0,
    fetch_details: bool = False
) -> List[Dict[str, str]]:
    """æ¥½å¤©HTMLã‹ã‚‰ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    products_with_info = extract_rakuten_products_from_html(html_path)
    
    if not products_with_info:
        print("âš ï¸ æ¥½å¤©å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return []
    
    print(f"âœ… {len(products_with_info)}ä»¶ã®æ¥½å¤©å•†å“ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
    
    product_items = products_with_info[skip_count:]
    
    if not product_items:
        print("âš ï¸ å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆåºƒå‘Šé™¤å¤–å¾Œï¼‰")
        return []
    
    print(f"ðŸ“¦ {len(product_items)}ä»¶ã®å•†å“ã‚’å‡¦ç†ã—ã¾ã™ï¼ˆåºƒå‘Š{skip_count}ä»¶ã‚’é™¤å¤–ï¼‰")
    
    products = []
    
    if fetch_details:
        def fetch_product_info(item_id: str, shop_id: str, title_from_html: str) -> Tuple[str, Dict]:
            try:
                product_info = get_rakuten_product_info(item_id, shop_id)
                if not product_info.get("title") or len(product_info.get("title", "")) < 5:
                    product_info["title"] = title_from_html
                return (item_id, product_info)
            except Exception:
                url = f"https://item.rakuten.co.jp/{shop_id}/{item_id}/" if shop_id else f"https://item.rakuten.co.jp/c/{item_id}/"
                return (item_id, {
                    "item_id": item_id,
                    "shop_id": shop_id,
                    "title": title_from_html,
                    "url": url,
                    "price": "",
                    "image_url": ""
                })
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = {
                executor.submit(fetch_product_info, item_id, shop_id, title): (item_id, shop_id, title)
                for item_id, shop_id, title in product_items
            }
            
            for future in as_completed(futures.keys()):
                item_id, shop_id, title = futures[future]
                item_id_result, product_info = future.result()
                products.append({
                    "index": len(products) + 1,
                    "item_id": item_id,
                    "shop_id": product_info.get("shop_id", shop_id),
                    "title": product_info.get("title", title),
                    "price": product_info.get("price", ""),
                    "image_url": product_info.get("image_url", ""),
                    "affiliate_link": create_rakuten_affiliate_link(
                        item_id,
                        product_info.get("shop_id", shop_id),
                        affiliate_id
                    ),
                    "rakuten_url": product_info.get("url", f"https://item.rakuten.co.jp/c/{item_id}/")
                })
    else:
        for idx, (item_id, shop_id, title) in enumerate(product_items, 1):
            products.append({
                "index": idx,
                "item_id": item_id,
                "shop_id": shop_id,
                "title": title,
                "price": "",
                "image_url": "",
                "affiliate_link": create_rakuten_affiliate_link(item_id, shop_id, affiliate_id),
                "rakuten_url": f"https://item.rakuten.co.jp/{shop_id}/{item_id}/" if shop_id else f"https://item.rakuten.co.jp/c/{item_id}/"
            })
    
    return products


def save_to_json(products: List[Dict[str, str]], output_path: Path):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    output_path.write_text(
        json.dumps(products, ensure_ascii=False, indent=2),
        encoding='utf-8'
    )
    print(f"\nâœ… JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")


def save_to_csv(products: List[Dict[str, str]], output_path: Path, is_amazon: bool = True):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    import csv
    
    fieldnames = (
        ['index', 'asin', 'title', 'affiliate_link', 'amazon_url']
        if is_amazon
        else ['index', 'item_id', 'shop_id', 'title', 'affiliate_link', 'rakuten_url']
    )
    
    with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(products)
    
    print(f"\nâœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='Amazon/æ¥½å¤©å•†å“ä¸€è¦§HTMLã‹ã‚‰ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ')
    parser.add_argument('html_file', nargs='?', default='', help='HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--type', '-t', choices=['amazon', 'rakuten', 'auto'], default='auto', help='å•†å“ã‚¿ã‚¤ãƒ—ï¼ˆauto=è‡ªå‹•åˆ¤å®šï¼‰')
    parser.add_argument('--associate-id', '-a', default='', help='ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆIDï¼ˆAmazon: tag, æ¥½å¤©: s-idï¼‰')
    parser.add_argument('--skip', '-s', type=int, default=4, help='åºƒå‘Šå•†å“ã‚’é™¤å¤–ã™ã‚‹ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 4ï¼‰')
    parser.add_argument('--format', '-f', choices=['json', 'csv', 'both'], default='json', help='å‡ºåŠ›å½¢å¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: jsonï¼‰')
    parser.add_argument('--output', '-o', default='', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰')
    parser.add_argument('--fetch-details', action='store_true', help='å•†å“è©³ç´°æƒ…å ±ã‚’å–å¾—ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰')
    
    args = parser.parse_args()
    
    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ±ºå®š
    if args.html_file:
        html_path = Path(args.html_file)
    else:
        script_dir = Path(__file__).parent.parent
        html_files = sorted(script_dir.glob("*.html"), key=lambda f: f.stat().st_mtime, reverse=True)
        if not html_files:
            print("âŒ HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        html_path = html_files[0]
        print(f"ðŸ“„ ä½¿ç”¨ã™ã‚‹HTMLãƒ•ã‚¡ã‚¤ãƒ«: {html_path.name}")
    
    # å•†å“ã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•åˆ¤å®š
    if args.type == 'auto':
        product_type = detect_product_type(html_path)
        if not product_type:
            print("âš ï¸ å•†å“ã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•åˆ¤å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚--typeã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            return
    else:
        product_type = args.type
    
    print(f"ðŸ›’ å•†å“ã‚¿ã‚¤ãƒ—: {product_type}")
    
    # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ
    if product_type == 'amazon':
        products = generate_amazon_affiliate_links(html_path, args.associate_id, args.skip, args.fetch_details)
        is_amazon = True
    else:
        products = generate_rakuten_affiliate_links(html_path, args.associate_id, args.skip, args.fetch_details)
        is_amazon = False
    
    if not products:
        print("âŒ å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®š
    if args.output:
        output_base = Path(args.output)
    else:
        output_base = html_path.stem + f"_{product_type}_affiliate_links"
    
    # ä¿å­˜
    if args.format in ['json', 'both']:
        json_path = html_path.parent / f"{output_base}.json"
        save_to_json(products, json_path)
    
    if args.format in ['csv', 'both']:
        csv_path = html_path.parent / f"{output_base}.csv"
        save_to_csv(products, csv_path, is_amazon)
    
    print(f"\nðŸ“Š å‡¦ç†å®Œäº†: {len(products)}ä»¶ã®å•†å“ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
